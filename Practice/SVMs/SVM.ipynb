{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of the [Machine Learning class](https://github.com/erachelson/MLclass) by [Emmanuel Rachelson](https://personnel.isae-supaero.fr/emmanuel-rachelson?lang=en).\n",
    "\n",
    "This notebook is joint work by Erwan Lecarpentier, Luca Mossina and Emmanuel Rachelson.\n",
    "\n",
    "License: CC-BY-SA-NC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:22pt; line-height:25pt; font-weight:bold; text-align:center;\">Support Vector Machines (practice session)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "SVMs is a classical Supervised Learning technique.\n",
    "\n",
    "Content:\n",
    "1. [Linear SVMs](#sec1)<br>\n",
    "1.1 [Let's play](#subsec11)<br>\n",
    "1.2 [Tune your linear SVM](#subsec12)\n",
    "2. [SVM with kernels](#sec2)<br>\n",
    "2.1 [Warm-up: Americans and Atheism  (OPTIONAL)](#subsec21)<br>\n",
    "2.2 [Back to basics](#subsec22)<br>\n",
    "2.3 [Kernels](#subsec23)\n",
    "3. [Application](#sec3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec1\"></a> 1. Linear SVMs\n",
    "\n",
    "The goal of this section is to explore the most basic form of SVM, namely the linear one. We are going to test this method on a toy data set and to play with the hyperparameters in order to get the best classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Question 1.1**<br>\n",
    "What is the objective of SVMs?<br>\n",
    "On which principle is it built? Give an **intuitive** geometrical interpretation.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"subsec11\"></a> 1.1 Let's play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a toy data set $\\{ {x_i, y_i} \\}_{i=1}^n$ where $x_i \\in \\mathbb{R}^2$ is a point and $y_i \\in [-1, 1]$ a class.<br>\n",
    "The code below allows you to load the data and to display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig_size = (6,6)\n",
    "\n",
    "csv_file_name=\"data/data1.csv\"\n",
    "res = np.loadtxt(csv_file_name, delimiter=',')\n",
    "X = res[:,0:-1]\n",
    "y = res[:,-1].astype(int)\n",
    "Xblue = X[y==-1]\n",
    "Xred  = X[y==+1]\n",
    "fig = plt.figure(figsize=fig_size, dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.scatter(Xblue[:,0], Xblue[:,1], c='c', s=20)\n",
    "plt.scatter(Xred[:, 0], Xred[:, 1], c='r', s=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Question 1.1.1**<br>\n",
    "Can this data set be completely separated by a straight line?<br>\n",
    "What kind of technique could be used to train a classifier on this data set?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply the SVM method to this dataset. To this purpose, we are going to use scikit-learn, a Python library providing most of the common Machine Learning off the shelf methods including SVM.  \n",
    "Their documentation page for this method can be found here: http://scikit-learn.org/stable/modules/svm.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Question 1.1.2**<br>\n",
    "Use the class sklearn.svm.SVC provided in scikit-learn in order to train an SVM on the provided data.\n",
    "Try to display the separating hyperplane on this dataset. You can get inspiration from the SVM course's code.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/code1.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Question 1.1.3**<br>\n",
    "In \"Support Vector Machine\", what are the \"support vectors\"?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"subsec12\"></a> 1.2 Tune your linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the parameters of the class sklearn.svm.SVC is the penalty parameter $C$ of the error term. It quantifies the missmatch-tolerance that is allowed when fitting an SVM model to the data. The smaller, the bigger is the tolerance. In our case, having such a tolerance is necessary because the data cannot be separated by a straight line, thus some point have to be on the wrong side of the separating hyperplan.\n",
    "\n",
    "$C$ is an hyperparameter, which means that it needs to be tuned for the algorithm to yield good results. This is a common concern in Machine Learning, as a result, techniques have been designed in order to select the best hyperparameters. The most common technique is probably the cross validation. Roughly it consists in:\n",
    "\n",
    "    0) dividing the data set into training and test sets;\n",
    "\n",
    "    1) selecting a value of the hyperparameters;\n",
    "\n",
    "    2) train the model with the training set;\n",
    "\n",
    "    3) test the model with the test set and compute a performance indicator;\n",
    "\n",
    "    4) go back to 1) with another value of the hyperparameters.\n",
    "\n",
    "When the procedure is finished, simply choose the hyperparameters yielding the best performance. We are now going to perform k-fold cross validation - which is a certain type of cross validation - on our problem, in order to identify the best value of $C$.\n",
    "For more details, see the wikipedia article: https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation\n",
    "\n",
    "For more details on the type of indicators used in step 3), see https://en.wikipedia.org/wiki/Evaluation_of_binary_classifiers<br>\n",
    "The accuracy, refered to as ACC in the article, may be a good start (and most scikit-learn classifiers implement it directly via the [`score` function](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.score))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Question 1.2.1**<br>\n",
    "Fill the code below in order to find the best value of the hyperparameter $C$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [0.001, 0.01, 0.1, 1.0, 10, 25, 30, 42, 100, 1000] # Tested values of C\n",
    "k = 10 # k-fold CV: number of subsets\n",
    "n = int(len(X)/k) # length of subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/code2.py\n",
    "### WRITE YOUR CODE HERE - implement your own version of k-fold cross-validation.\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Question 1.2.2**<br>\n",
    "What is the best value of $C$ among the proposed ones?<br>\n",
    "What can you expect from the curve of the accuracy as a function of $C$ if you used a finer meshing for $C$?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec2\"></a> 2. SVMs with kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The natural application of SVM methods is that of binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"subsec21\"></a> 2.1 Warm-up: Americans and Atheism  (OPTIONAL)\n",
    "\n",
    "**SCOPE**: warm-up, revise and challenge yourself with a simple example.\n",
    "    - MAXIMUM TIME: 10 minutes, afterwards look at the proposed solution.\n",
    "\n",
    "Let us find out how americans tolerated atheists in 1976.\n",
    "The dataset is described as follows:\n",
    "\n",
    "```\n",
    "Dataset:  atheist.dat\n",
    "Source: E. Filsinger (1976). \"Tolerance of Non-Believers: A Cross-Tabular  and Log Linear Analysis of Some Religious Correlates,\" Review of Religious  Research, Vol.17, #3, pp.232-240\n",
    "Description: Church Attendance and Tolerance for Atheists for survey of 1221 people.\n",
    "\n",
    "Variables/Columns \n",
    "Church Attendance  8  /* 1=Never, 2=Yearly, 3=Monthly, 4=Weekly */\n",
    "Tolerance for Atheists  16 /* 1=Low, 2=High  */\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Retrieve and understand data\n",
    "\n",
    "The file is available online at: http://users.stat.ufl.edu/~winner/datasets.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Question 2.1.1.1**<br>\n",
    "Import the data as a pandas dataframe. No cheating, it can be done with a pandas function (one line).\n",
    "Your dataframe should have 1221 rows and 2 columns, which you'll name respectively 'attendance', 'tolerance'.\n",
    "<br><br>\n",
    "Plot the data. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# %load solutions/code3.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't look like the fancy figures we saw in class, does it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Run SVM. Does it make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Question 2.1.2.1**<br>\n",
    "First of all, what can we learn having a strong look at the data and their description?\n",
    "<br>\n",
    "Do we have categorical, binary, continuous data?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are fundamental questions, which you'll ask yourselves for the rest of your (data science) life.\n",
    "Often, collegues or clients have no idea about these formalities; they have a problem and they ask you to provide a good enough solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the fun begin. We want to do SVM classification with scikit-learn, but we've already forgotten its api!  \n",
    "Thou shalt fear no more, the word of the Doc is with us:\n",
    "http://scikit-learn.org/stable/modules/classes.html#module-sklearn.svm\n",
    "\n",
    "We are doing SVM classification, could it be: http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC ?\n",
    "Let us copy-paste the example at the bottom of the page. Run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait, what are `X` and `y`? \n",
    "Let us take a moment to ponder on how to name things.  \n",
    "For sure, \"x\" and \"y\" mean something to all those with scientific background.  \n",
    "Often, however, when we do some ML modeling, we are having a data-dialogue with someone, ourselves included.  \n",
    "Do the favor to the \"you\" of the future and use a meaningful description for the variables; code is mostly meant to be read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attend = df['attendance'] # WARNING: you are passing a reference.\n",
    "toler  = df['tolerance']\n",
    "\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(X = attend,\n",
    "        y = toler) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something just went horribly wrong.  \n",
    "He's telling us something about ```\"Expected 2D array, got 1D array instead: [...]\"```  \n",
    "After some intense googling, stackoverflow.com gives us a hint:  \n",
    "https://stackoverflow.com/questions/38657138/scikits-learn-svm-1-dimensional-separating-hyperplane\n",
    "\n",
    "Let us add a dummy column of zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['zeros'] = 0 # dummy zeros\n",
    "\n",
    "df  = df.sample(frac=1) # shuffle rows to avoid introducing bias\n",
    "print(df.iloc[0:5,])\n",
    "\n",
    "NTRAINS = 800 # out of 1221\n",
    "\n",
    "tr = df.iloc[0:NTRAINS,:] # training data\n",
    "te = df.iloc[NTRAINS: ,:] # testing data\n",
    "\n",
    "# assert: make sure now rows were lost or doubled\n",
    "assert tr.shape[0] + te.shape[0] == df.shape[0]\n",
    "\n",
    "features = ['attendance', 'zeros']\n",
    "attend = df[features]\n",
    "toler  = df['tolerance']\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(tol=1e-5) # linear\n",
    "# __uncomment__ if you want to try with nonlinear SVM:\n",
    "# clf = SVC(gamma='auto')\n",
    "\n",
    "clf.fit(X=attend[0:NTRAINS], y=toler[0:NTRAINS]) \n",
    "\n",
    "y_pred = clf.predict(attend[NTRAINS:])\n",
    "y_test = toler[NTRAINS:].tolist()\n",
    "\n",
    "errors = np.zeros(len(y_pred))\n",
    "\n",
    "for i in range(len(errors)):\n",
    "    if y_pred[i] != y_test[i]:\n",
    "        errors[i] = 1\n",
    "        \n",
    "er_rate = np.sum(errors) / len(errors)\n",
    "print(\"error rate:\", er_rate)\n",
    "print(\" --> about \", int(er_rate*100), \"% of the predictions were not correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Campeones*, we made it, sklearn is no more mad at us.  \n",
    "Did we get anything interesting? Are we learning something at all?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**--> Lesson learned: some data are more svm-able than others**\n",
    "\n",
    "Although SVM's are among the best tools in machine learning, we cannot expect it to work great in all cases.  \n",
    "Much more could be done, tuning parameters or changing kernels, but let's go on to more interesting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus: beware of the Python   \n",
    "Let's look at what done just before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute and ignore the following two lines\n",
    "import copy            # IGNORE\n",
    "dF = copy.deepcopy(df) # IGNORE\n",
    "\n",
    "mangueira = dF['attendance'] # WARNING: you are passing a reference.\n",
    "portela   = dF['tolerance']\n",
    "\n",
    "# See how dangerous things can get:\n",
    "print(mangueira[0:2])\n",
    "mangueira[0:2] = 666, 666\n",
    "print(dF.iloc[0:2]) # original df is modified!!\n",
    "\n",
    "# Possible solution:\n",
    "import copy\n",
    "mangueira = copy.deepcopy(df['attendance'])\n",
    "# all data is hard copied in new struct: can be a problem, if data is big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us move to more serious matters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"subsec22\"></a> 2.2 Back to basics (OPTIONAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After our previous little experiments, it is time to start gaining some insight into the use of kernels.  \n",
    "But what _is_ a kernel? Can we get an intuitive image of what these kernels are doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPOINTS = 100\n",
    "COLORS  = ['pink', \"green\"]\n",
    "\n",
    "# Generate toy data\n",
    "x = np.random.rand(NPOINTS)\n",
    "y = np.ones(NPOINTS, dtype=int)\n",
    "for i in range(NPOINTS):\n",
    "    if x[i] < 0.0666 or x[i] > 0.666:\n",
    "        y[i] = -1\n",
    "        \n",
    "# Plot toy data: we have a one-dimensional problem\n",
    "plt.scatter(x[y==-1], np.zeros(len(x[y==-1])), color=COLORS[0])\n",
    "plt.scatter(x[y== 1], np.zeros(len(x[y==1])), color=COLORS[1])\n",
    "plt.xlabel('x');plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple linear separator, a point in this example, cannot be found to separate the data.  \n",
    "However we can easily see that the limit between the pink and the green regions are well defined.  \n",
    "How can we **transform** the data to make this linear separation possible? We can apply a function $f : x_i \\mapsto f(x_i)$ on each data point. Such function is called **feature** of the data.  \n",
    "Let us try with a polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = 1, 1, 1\n",
    "feature = a*x**2 + b*x + c\n",
    "\n",
    "plt.scatter(x[y==-1], feature[y==-1], color=COLORS[0])\n",
    "plt.scatter(x[y== 1], feature[y== 1], color=COLORS[1])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = -8, 1, 2\n",
    "feature = a*x**2 + b*x + c\n",
    "\n",
    "plt.scatter(x[y==-1], feature[y==-1], color=COLORS[0])\n",
    "plt.scatter(x[y== 1], feature[y== 1], color=COLORS[1])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Question 2.2.1**<br>\n",
    "Copy the code above and play manually with the parameters in order to make the features separable.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = ?,?,?\n",
    "feature = a*x**2 + b*x + c\n",
    "\n",
    "colors = ['pink', \"green\"]\n",
    "\n",
    "plt.scatter(x[y==-1], feature[y==-1], color=COLORS[0])\n",
    "plt.scatter(x[y== 1], feature[y== 1], color=COLORS[1])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "\n",
    "height = 0.90\n",
    "plt.plot([0,1], [height, height], color='red')\n",
    "height = 0.95\n",
    "plt.plot([0,1], [height, height], color='blue')\n",
    "height = 1.00\n",
    "plt.plot([0,1], [height, height], color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wouldn't be nice to have an algorithm doing that for us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"subsec23\"></a> 2.3 Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's play with the kernels in scikit-learn. As before, we are going to use the sklearn.svm.SVC class in order to fit SVMs to some data models. The 'kernel' attribute of the class allows you to use different kernels for the used models.\n",
    "\n",
    "Below are displayed several data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(csv_file_name):\n",
    "    fig_size = (6, 6)\n",
    "    res = np.loadtxt(csv_file_name, delimiter=',')\n",
    "    X = res[:,0:-1]\n",
    "    y = res[:,-1].astype(int)\n",
    "    Xblue = X[y==-1]\n",
    "    Xred  = X[y==+1]\n",
    "    fig = plt.figure(figsize=fig_size, dpi=80, facecolor='w', edgecolor='k')\n",
    "    plt.scatter(Xblue[:,0], Xblue[:,1], c='c', s=20)\n",
    "    plt.scatter(Xred[:, 0], Xred[:, 1], c='r', s=20)\n",
    "\n",
    "plot_data(\"data/data2.csv\")\n",
    "plot_data(\"data/data3.csv\")\n",
    "plot_data(\"data/data4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Question 2.3.1**<br>\n",
    "Find a good kernel for each one of the data set above.<br><br>\n",
    "**Hint 1**: you can reuse the `plot_SVC` function provided in class that plots the decision frontier of the model and the data set $(X, y)$.<br><br>\n",
    "**Hint 2**: sometimes, the default kernels provided by scikit-learn are not enough. In this case, you can design a special kernel for your problem using the a callable function. See [here](http://scikit-learn.org/stable/auto_examples/svm/plot_custom_kernel.html) for an example. Recall that $k(x,x')$ measures how close $x$ and $x'$ are in the kernel's projection space: keeping this in mind can help you shape a good projection first, and then deriving a good kernel.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myplot import plot_SVC\n",
    "\n",
    "def load_data(filename):\n",
    "    res = np.loadtxt(filename, delimiter=',')\n",
    "    X = res[:,0:-1]\n",
    "    y = res[:,-1].astype(int)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/code4.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Question 2.3.2**<br>\n",
    "Can you hint a method for robustly selecting the best kernel and or the hyperparameters of the kernel function.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec3\"></a> 3. Application: Binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now try to do binary classification on the Mushrooms data set loaded below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/mushrooms.csv\")\n",
    "data.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 classes, namely $y_i \\in \\{ e, p \\}$ and many weird values for the elements of $x_i$.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Question 3.1**<br>\n",
    "Use LabelEncoder from sklearn.preprocessing in order to turn the elements of $x_i$ into numerical values.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/code5.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Question 3.2**<br>\n",
    "Use StandardScaler from sklearn.preprocessing in order to scale the data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/code6.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">**Question 3.3**<br>\n",
    "Now train an SVM classifier on the data. Try several different kernels and measure the accuracy of your predictor.<br>\n",
    "**Hint:** You can split your data set into a training and testing set using train_test_split from sklearn.model_selection\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/code7.py\n",
    "### WRITE YOUR CODE HERE\n",
    "# If you get stuck, uncomment the line above to load a correction in this cell (then you can execute this code).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
